(base) [garam_icecream@garam-icecream COMSYS-Hackathon]$ python -u "/home/garam_icecream/DaSH/COMSYS-Hackathon/CNN_task_A/main.py"
{'female': 0, 'male': 1}
{'female': 0, 'male': 1}
cuda
1, 1, loss : 2.326460123062134
1, 11, loss : 2.2698204083876177
1, 21, loss : 2.1807871148699807
1, 31, loss : 1.8819542296471135
1, 41, loss : 1.5835257808609706
1, 51, loss : 1.3723886804837806
1, 61, loss : 1.2450092149302974
1, 71, loss : 1.1910214002480284
1, 81, loss : 1.122022924433106
1, 91, loss : 1.0442765989791152
1, 101, loss : 0.9972753924741825
1, 111, loss : 0.9583841593273252
1, 121, loss : 0.9052242046907113
1, 131, loss : 0.8794764415787547
1, 141, loss : 0.8625872657330482
1, 151, loss : 0.8376798676234355
1, 161, loss : 0.7928950399339708
1, 171, loss : 0.7774690975140977
1, 181, loss : 0.7652970084339092
1, 191, loss : 0.7518804720407888
1, 201, loss : 0.7467101964640862
1, 211, loss : 0.7337497173614306
1, 221, loss : 0.7222644867674696
1, 231, loss : 0.7054556976798196
1, 241, loss : 0.6943655233787706
1, 251, loss : 0.6886303667888134
1, 261, loss : 0.6863676471389487
1, 271, loss : 0.6737350698550166
1, 281, loss : 0.670031268187729
1, 291, loss : 0.6607893495404408
1, 301, loss : 0.6512223006615978
1, 311, loss : 0.639637416376885
1, 321, loss : 0.6341307150806385
1, 331, loss : 0.6320291687903244
1, 341, loss : 0.6250603586159472
1, 351, loss : 0.6082238833329765
1, 361, loss : 0.6062294773001564
1, 371, loss : 0.6036562800214116
1, 381, loss : 0.6007950115946471
1, 391, loss : 0.5971558753036611
1, 401, loss : 0.5947755623476445
1, 411, loss : 0.5897960730628937
1, 421, loss : 0.5851780819273034
1, 431, loss : 0.5774539738381389
1, 441, loss : 0.5732539370476507
1, 451, loss : 0.5670707811427999
1, 461, loss : 0.5625162644548152
1, 471, loss : 0.5535206645559084
1, 481, loss : 0.549335037208048
2, 1, loss : 0.5137147903442383
2, 11, loss : 0.42162853343920276
2, 21, loss : 0.4157936642212527
2, 31, loss : 0.3685292950981567
2, 41, loss : 0.39003880883044584
2, 51, loss : 0.4057904804563698
2, 61, loss : 0.392115492297367
2, 71, loss : 0.39101199400414466
2, 81, loss : 0.4020039923834028
2, 91, loss : 0.4052178778552583
2, 101, loss : 0.40571685363123616
2, 111, loss : 0.4072263095074812
2, 121, loss : 0.40486282029396986
2, 131, loss : 0.39884205685061125
2, 141, loss : 0.4100349738282409
2, 151, loss : 0.4037769604289275
2, 161, loss : 0.41180917654788085
2, 171, loss : 0.40684329545702674
2, 181, loss : 0.3902962054807734
2, 191, loss : 0.3951831761618384
2, 201, loss : 0.398478372892439
2, 211, loss : 0.39861353978369013
2, 221, loss : 0.3982058774450229
2, 231, loss : 0.3991504902921182
2, 241, loss : 0.3944415503801755
2, 251, loss : 0.3965994346751442
2, 261, loss : 0.39680631147872414
2, 271, loss : 0.39584711867872613
2, 281, loss : 0.39202650326463223
2, 291, loss : 0.38754185613587216
2, 301, loss : 0.3910535210024169
2, 311, loss : 0.38994485000223283
2, 321, loss : 0.38314342269502766
2, 331, loss : 0.38764466178108264
2, 341, loss : 0.3841701846104115
2, 351, loss : 0.3909958389307773
2, 361, loss : 0.3914857742594622
2, 371, loss : 0.3863140993225677
2, 381, loss : 0.38362232535366175
2, 391, loss : 0.3833975463258841
2, 401, loss : 0.3847979658458642
2, 411, loss : 0.3820068283791715
2, 421, loss : 0.380268902133491
2, 431, loss : 0.38180855070262404
2, 441, loss : 0.3791270353002453
2, 451, loss : 0.3805104814735169
2, 461, loss : 0.3826778202490384
2, 471, loss : 0.3791953521803409
2, 481, loss : 0.3790407162454955
Finished Training
Accuracy of the network on the 10000 test images: 81 %